schema: '2.0'
stages:
  data_preparation:
    cmd: py -m src.pipelines.data_preparation --config=params.yaml --input-dir=data\raw
      --output-dir=data\prepared
    deps:
    - path: data\raw
      md5: 63aecd37950ec75d992549d925068acd.dir
      size: 412284
      nfiles: 50
    - path: src\pipelines\data_preparation.py
      md5: ec85488bc3dddf943d225f8af760db7e
      size: 1184
    params:
      params.yaml:
        data_preparation:
    outs:
    - path: data\prepared
      md5: 72bcb1e643859ea2c62bcd12c9eb9c27.dir
      size: 7645904
      nfiles: 50
  data_splitting:
    cmd: py -m src.pipelines.data_splitting --config=params.yaml --input-dir=data\prepared
      --output-dir=data\split
    deps:
    - path: data\prepared
      md5: 72bcb1e643859ea2c62bcd12c9eb9c27.dir
      size: 7645904
      nfiles: 50
    - path: src\pipelines\data_splitting.py
      md5: 15f4530fb01c9153f3d8db87847dbded
      size: 1668
    params:
      params.yaml:
        data_splitting:
          batch_size: 32
          color_mode: rgb
          image_size:
          - 256
          - 256
          shuffle: true
          train_seed: 0
          valid_seed: 42
          validation_split: 0.2
    outs:
    - path: data\split
      md5: cf3d35de5d636e740a435caeb8072a07.dir
      size: 39322212
      nfiles: 6
  data_valid_preprocessing:
    cmd: py -m src.pipelines.data_valid_preprocessing --config=params.yaml --input-dir=data\split
      --output-dir=data\preprocessed
    deps:
    - path: data\split\valid
      md5: 96d207f89208707f5541f8a609964703.dir
      size: 7864531
      nfiles: 3
    - path: src\pipelines\data_valid_preprocessing.py
      md5: 4e9223e54235c9d08bfc3dec6c8777de
      size: 1393
    params:
      params.yaml:
        data_valid_preprocessing:
        - name: Rescaling
          scale: 0.00392156862745098
    outs:
    - path: data\preprocessed\valid
      md5: 71751c0c8e44b95b9dc53b1d427819e5.dir
      size: 7864532
      nfiles: 3
  data_train_preprocessing:
    cmd: py -m src.pipelines.data_train_preprocessing --config=params.yaml --input-dir=data\split
      --output-dir=data\preprocessed
    deps:
    - path: data\split\train
      md5: 74d802fc4fd1678d5721f62f983a128c.dir
      size: 31457681
      nfiles: 3
    - path: src\pipelines\data_train_preprocessing.py
      md5: 61b8581b80f6fd00d56d3bca2e46e06a
      size: 1324
    params:
      params.yaml:
        data_train_preprocessing:
        - name: Rescaling
          scale: 0.00392156862745098
        - mode: horizontal_and_vertical
          name: RandomFlip
        - factor: 0.2
          name: RandomRotation
    outs:
    - path: data\preprocessed\train
      md5: 25a40a28935f648cb752cd3221e1c10d.dir
      size: 31457682
      nfiles: 3
  model_training:
    cmd: py -m src.pipelines.model_training --config=params.yaml --input-dir=data\preprocessed
      --model-dir=mlruns
    deps:
    - path: data\preprocessed\train
      md5: 25a40a28935f648cb752cd3221e1c10d.dir
      size: 31457682
      nfiles: 3
    - path: src\pipelines\model_training.py
      md5: a7ac7ccecdead6f41cbb14e0296ed865
      size: 2956
    params:
      params.yaml:
        model_training:
          compiler:
            loss: sparse_categorical_crossentropy
            metrics:
            - accuracy
            optimizer: RMSprop
          experiment: exp_3d
          input_shape:
            image_height: 256
            image_width: 256
            n_channels: 3
          model_cfg:
          - activation: relu
            filters: 32
            kernel_size: 3
            name: Conv2D
            padding: same
            strides: 2
          - name: BatchNormalization
          - name: MaxPooling2D
            pool_size:
            - 2
            - 2
          - name: BatchNormalization
          - activation: relu
            filters: 64
            kernel_size: 3
            name: Conv2D
            padding: same
            strides: 1
          - name: BatchNormalization
          - name: MaxPooling2D
            pool_size:
            - 2
            - 2
          - name: BatchNormalization
          - activation: relu
            filters: 128
            kernel_size: 3
            name: Conv2D
            padding: same
            strides: 1
          - name: BatchNormalization
          - name: MaxPooling2D
            pool_size:
            - 2
            - 2
          - name: BatchNormalization
          - name: Flatten
          - activation: relu
            name: Dense
            units: 256
          - name: BatchNormalization
          - name: Dropout
            rate: 0.5
          - activation: softmax
            name: Dense
            units: 10
          training_cfg:
            batch_size: 32
            epochs: 1
    outs:
    - path: mlruns
      md5: 743bb0ad6f3be939632bf76c034ba32c.dir
      size: 68347060
      nfiles: 42
  model_evaluation:
    cmd: py -m src.pipelines.model_evaluation --config=params.yaml --input-dir=data\preprocessed
      --model-dir=mlruns
    deps:
    - path: data\preprocessed\valid
      md5: 71751c0c8e44b95b9dc53b1d427819e5.dir
      size: 7864532
      nfiles: 3
    - path: mlruns
      md5: 743bb0ad6f3be939632bf76c034ba32c.dir
      size: 68347060
      nfiles: 42
    - path: src\pipelines\model_evaluation.py
      md5: 608c7d3f412f666ce47a5757cb30e608
      size: 1571
    params:
      params.yaml:
        model_evaluation:
          batch_size: 32
          exp_id: '1'
          run_id: 89753933977f42d6919e727bfd294ce7
