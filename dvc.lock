schema: '2.0'
stages:
  data_preparation:
    cmd: py -m src.pipelines.data_preparation --config=params.yaml --input-dir=data\raw
      --output-dir=data\prepared
    deps:
    - path: data\raw
      md5: 63aecd37950ec75d992549d925068acd.dir
      size: 412284
      nfiles: 50
    - path: src\pipelines\data_preparation.py
      md5: 23f4cce320b2feb2c6daf6b6c7b6b077
      size: 1191
    params:
      params.yaml:
        data_preparation:
          data_formatter: PngFormatter
    outs:
    - path: data\prepared
      md5: 72bcb1e643859ea2c62bcd12c9eb9c27.dir
      size: 7645904
      nfiles: 50
  data_splitting:
    cmd: py -m src.pipelines.data_splitting --config=params.yaml --input-dir=data\prepared
      --output-dir=data\split
    deps:
    - path: data\prepared
      md5: 72bcb1e643859ea2c62bcd12c9eb9c27.dir
      size: 7645904
      nfiles: 50
    - path: src\pipelines\data_splitting.py
      md5: 81add19d0ef66cd3e3f1a3ac85f830d8
      size: 1657
    params:
      params.yaml:
        data_splitting:
          batch_size: 32
          color_mode: rgb
          image_size:
          - 256
          - 256
          shuffle: true
          train_seed: 0
          valid_seed: 42
          validation_split: 0.2
    outs:
    - path: data\split
      md5: 395cbb600ecc3fd46e6d6331c3186b0d.dir
      size: 39322213
      nfiles: 6
  data_valid_preprocessing:
    cmd: py -m src.pipelines.data_valid_preprocessing --config=params.yaml --input-dir=data\split
      --output-dir=data\preprocessed
    deps:
    - path: data\split\valid
      md5: f35ce97e2cc024451d700adcf345d8a0.dir
      size: 7864531
      nfiles: 3
    - path: src\pipelines\data_valid_preprocessing.py
      md5: 02db1ad375755223ed20a5ba23ea63d1
      size: 1427
    params:
      params.yaml:
        data_valid_preprocessing:
        - name: Rescaling
          scale: 0.00392156862745098
    outs:
    - path: data\preprocessed\valid
      md5: e31ef31f4e56404a9845dcbf9d701dc0.dir
      size: 7864532
      nfiles: 3
  data_train_preprocessing:
    cmd: py -m src.pipelines.data_train_preprocessing --config=params.yaml --input-dir=data\split
      --output-dir=data\preprocessed
    deps:
    - path: data\split\train
      md5: 19937bd91e05e231447db7201735a95d.dir
      size: 31457682
      nfiles: 3
    - path: src\pipelines\data_train_preprocessing.py
      md5: 5a0b11afd9d85e4c663c5c3eb3e205fd
      size: 1358
    params:
      params.yaml:
        data_train_preprocessing:
        - name: Rescaling
          scale: 0.00392156862745098
        - mode: horizontal_and_vertical
          name: RandomFlip
        - factor: 0.2
          name: RandomRotation
    outs:
    - path: data\preprocessed\train
      md5: 274a4bda970e8162fba8770fdb07eeca.dir
      size: 31457682
      nfiles: 3
  model_training:
    cmd: py -m src.pipelines.model_training --config=params.yaml --input-dir=data\preprocessed
      --model-dir=mlruns
    deps:
    - path: data\preprocessed\train
      md5: 274a4bda970e8162fba8770fdb07eeca.dir
      size: 31457682
      nfiles: 3
    - path: src\pipelines\model_training.py
      md5: 57d65ffcd4d2e6ace96ed8e92ac210f6
      size: 2986
    params:
      params.yaml:
        model_training:
          compiler:
            loss: sparse_categorical_crossentropy
            metrics:
            - accuracy
            optimizer: RMSprop
          experiment: exp-1
          input_shape:
            image_height: 256
            image_width: 256
            n_channels: 3
          model_cfg:
          - activation: relu
            filters: 32
            kernel_size: 3
            name: Conv2D
            padding: same
            strides: 2
          - name: BatchNormalization
          - name: MaxPooling2D
            pool_size:
            - 2
            - 2
          - name: BatchNormalization
          - activation: relu
            filters: 64
            kernel_size: 3
            name: Conv2D
            padding: same
            strides: 1
          - name: BatchNormalization
          - name: MaxPooling2D
            pool_size:
            - 2
            - 2
          - name: BatchNormalization
          - activation: relu
            filters: 128
            kernel_size: 3
            name: Conv2D
            padding: same
            strides: 1
          - name: BatchNormalization
          - name: MaxPooling2D
            pool_size:
            - 2
            - 2
          - name: BatchNormalization
          - name: Flatten
          - activation: relu
            name: Dense
            units: 256
          - name: BatchNormalization
          - name: Dropout
            rate: 0.5
          - activation: softmax
            name: Dense
            units: 10
          run_name: smthg
          training_cfg:
            batch_size: 32
            epochs: 2
    outs:
    - path: mlruns
      md5: 3a6492da97f13d0dbfa8301060ca6502.dir
      size: 751819609
      nfiles: 481
  model_evaluation:
    cmd: py -m src.pipelines.model_evaluation --config=params.yaml --input-dir=data\preprocessed
      --model-dir=mlruns
    deps:
    - path: data\preprocessed\valid
      md5: e31ef31f4e56404a9845dcbf9d701dc0.dir
      size: 7864532
      nfiles: 3
    - path: mlruns
      md5: 3a6492da97f13d0dbfa8301060ca6502.dir
      size: 751819609
      nfiles: 481
    - path: src\pipelines\model_evaluation.py
      md5: a543f76d23c6f18dfec8b6eb08317522
      size: 1582
    params:
      params.yaml:
        model_evaluation:
          batch_size: 32
          exp_id: '8'
          run_id: 7bc6bfd9ce574288842b4f3981009909
  test_op:
    cmd: echo smthg to print again
    deps:
    - path: data\raw
      md5: 63aecd37950ec75d992549d925068acd.dir
      size: 412284
      nfiles: 50
